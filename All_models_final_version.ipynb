{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988b0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "class SensoryNeurons(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_neurons, in_dim = 1, plastic = True, params = (5, -2.5)):\n",
    "        super(SensoryNeurons, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.plastic = plastic\n",
    "        self.params = params\n",
    "        self.num_neurons = num_neurons\n",
    "\n",
    "        self.linear = nn.Linear(self.in_dim,self.num_neurons, bias = True)\n",
    "        self.resp_func = nn.Sigmoid()\n",
    "\n",
    "        if not self.plastic:\n",
    "            self.set_linear_weights()\n",
    "            self.linear.weight.requires_grad = False\n",
    "        \n",
    "    def set_linear_weights(self):\n",
    "        \n",
    "        self.linear.weight = torch.nn.Parameter(data = self.params[0] + 0.2*torch.randn(self.num_neurons,1), requires_grad = False)\n",
    "        self.linear.bias = torch.nn.Parameter(data = self.params[1] + 0.2*torch.randn(self.num_neurons), requires_grad = False)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = self.resp_func(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "class SensoryPopulation(nn.Module):\n",
    "    def __init__(self, num_neurons, plastic = True, population_ratio = 0.5):\n",
    "        super(SensoryPopulation, self).__init__()\n",
    "        \n",
    "        self.num_neurons = num_neurons\n",
    "        self.plastic = plastic\n",
    "        self.num_neurons_group1 = round(self.num_neurons * population_ratio)\n",
    "        self.num_neurons_group2 = round(self.num_neurons * (1.0 - population_ratio))\n",
    "        self.sensory_neurons_1 = SensoryNeurons(num_neurons = self.num_neurons_group1, in_dim = 1, plastic = self.plastic, params = (5, -2.5))\n",
    "        self.sensory_neurons_2 = SensoryNeurons(num_neurons = self.num_neurons_group2, in_dim = 1, plastic = self.plastic, params = (-5, -2.5))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x1 = self.sensory_neurons_1(x)\n",
    "        x2 = self.sensory_neurons_2(x)\n",
    "        \n",
    "        out = torch.cat((x1, x2),dim = 1)       \n",
    "        \n",
    "        return out\n",
    "            \n",
    "        \n",
    "    \n",
    "class Readout(nn.Module):\n",
    "    def __init__(self,num_classes = 2, in_dim = 10, readout_plastic = False, gain_plastic = False, bias_plastic = False):\n",
    "        super(Readout, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.in_dim = in_dim\n",
    "        self.readout_plastic = readout_plastic\n",
    "        self.gain_plastic = gain_plastic\n",
    "        self.bias_plastic = bias_plastic\n",
    "        \n",
    "        self.readout_layer = nn.Linear(self.in_dim, self.num_classes, bias = True)\n",
    "        self._set_weights()\n",
    "        \n",
    "    def _set_weights(self):\n",
    "        self.readout_bias = nn.Parameter(1*torch.ones(1),requires_grad=self.bias_plastic) #\n",
    "        self.readout_weight = (nn.Parameter(torch.ones(self.readout_layer.weight.shape)/(self.readout_layer.weight.shape[0]+self.readout_layer.weight.shape[1]),\n",
    "                                                 requires_grad=self.readout_plastic)) # model 3\n",
    "#         self.readout_weight = (nn.Parameter(0+(100*torch.randn(self.readout_layer.weight.shape)/(self.readout_layer.weight.shape[0]+self.readout_layer.weight.shape[1])),\n",
    "#                                                  requires_grad=self.readout_plastic)) # \n",
    "#         self.readout_layer.weight = nn.Parameter(torch.randn(self.readout_layer.weight.shape)/(self.readout_layer.weight.shape[0]+self.readout_layer.weight.shape[1]),\n",
    "#                                                  requires_grad=self.readout_plastic) # model 2\n",
    "#         self.readout_weight = (nn.Parameter(torch.cat(\n",
    "#                                             (-1*torch.ones(self.readout_layer.weight.shape[0],round(0.9*self.readout_layer.weight.shape[1])),\n",
    "#                                             torch.ones(self.readout_layer.weight.shape[0],round(0.3*self.readout_layer.weight.shape[1]))),\n",
    "#                                             dim=1)/(self.readout_layer.weight.shape[0]+self.readout_layer.weight.shape[1]),\n",
    "#                                             requires_grad=self.readout_plastic)) # model 2\n",
    "        self.readout_gain = nn.Parameter(torch.ones(1), requires_grad=self.gain_plastic)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return(nn.functional.linear(x, self.readout_gain * self.readout_weight, self.readout_bias))\n",
    "#         return (self.readout_layer(x))\n",
    "    \n",
    "    \n",
    "class Sensorimotor(nn.Module):\n",
    "    def __init__(self, num_sensory_neurons = 10, sensory_plastic = True, readout_plastic = False, gain_plastic = False, bias_plastic = False,sensory_pop_ratio = 0.5, num_classes = 2):\n",
    "        super(Sensorimotor, self).__init__()\n",
    "        \n",
    "        self.sensory_pop = SensoryPopulation(num_neurons = num_sensory_neurons, plastic = sensory_plastic, population_ratio = sensory_pop_ratio)\n",
    "        self.readout = Readout(num_classes = num_classes, in_dim = num_sensory_neurons, readout_plastic = readout_plastic, gain_plastic = gain_plastic, bias_plastic = bias_plastic)\n",
    "        self.sig = nn.Sigmoid()\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        sensory_out = self.sensory_pop(x)\n",
    "        readout_out = self.readout(sensory_out)\n",
    "#         print(readout_out)\n",
    "        y = self.sig(readout_out)\n",
    "#         y = self.softmax(readout_out)\n",
    "#         y = readout_out\n",
    "        \n",
    "        return y, readout_out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becd736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Stimulus(data.DataLoader):\n",
    "    def __init__(self, min_coherence = 0.8, max_coherence = 1):\n",
    "        \n",
    "        self.min_coherence = min_coherence\n",
    "        self.max_coherence = max_coherence\n",
    "        \n",
    "        self.NUM_SAMPLPES_PER_CATEGORY = 1000\n",
    "        \n",
    "        data1 = torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence\n",
    "        data2 = -(torch.rand(self.NUM_SAMPLPES_PER_CATEGORY)*(self.max_coherence - self.min_coherence) + self.min_coherence)\n",
    "#         target1 = torch.zeros(data1.shape, dtype = int)\n",
    "#         target2 = torch.ones(data2.shape, dtype = int)\n",
    "        target1 = torch.zeros(data1.shape)\n",
    "        target2 = torch.ones(data2.shape)\n",
    "        \n",
    "        self.data = torch.cat((data1, data2), dim = 0).unsqueeze(0).t()\n",
    "        self.target = torch.cat((target1, target2), dim = 0).unsqueeze(0).t()\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \n",
    "        return (self.data[index], self.target[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619aeeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMeter(object):\n",
    "    '''compute and show confusion matrix'''\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.mat = np.zeros((num_class, num_class))\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "\n",
    "    def update(self, pred, tar):\n",
    "        pred, tar = pred.cpu().numpy(), tar.cpu().numpy()\n",
    "        pred = np.squeeze(pred)\n",
    "        tar = np.squeeze(tar)\n",
    "        for p,t in zip(pred.flat, tar.flat):\n",
    "            self.mat[p][t] += 1\n",
    "\n",
    "    def print_mat(self):\n",
    "        print('Confusion Matrix: (target in columns)')\n",
    "        print(self.mat)\n",
    "\n",
    "    def plot_mat(self, path, dictionary=None, annotate=False):\n",
    "        plt.figure(dpi=600)\n",
    "        plt.imshow(self.mat,\n",
    "            cmap=plt.cm.jet,\n",
    "            interpolation=None,\n",
    "            extent=(0.5, np.shape(self.mat)[0]+0.5, np.shape(self.mat)[1]+0.5, 0.5))\n",
    "        width, height = self.mat.shape\n",
    "        if annotate:\n",
    "            for x in range(width):\n",
    "                for y in range(height):\n",
    "                    plt.annotate(str(int(self.mat[x][y])), xy=(y+1, x+1),\n",
    "                                 horizontalalignment='center',\n",
    "                                 verticalalignment='center',\n",
    "                                 fontsize=8)\n",
    "\n",
    "        if dictionary is not None:\n",
    "            plt.xticks([i+1 for i in range(width)],\n",
    "                       [dictionary[i] for i in range(width)],\n",
    "                       rotation='vertical')\n",
    "            plt.yticks([i+1 for i in range(height)],\n",
    "                       [dictionary[i] for i in range(height)])\n",
    "        plt.xlabel('Ground Truth')\n",
    "        plt.ylabel('Prediction')\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path, format='svg')\n",
    "        plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f231b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a75546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number = 1\n",
    "N_epoch_t = 100\n",
    "bias_all_mat = np.zeros((Number,int(N_epoch_t/10 +1)))\n",
    "accur_all_mat = np.zeros((Number,int(N_epoch_t/10 +1)))\n",
    "all_biases1 = torch.empty(Number)\n",
    "all_biases2 = torch.empty(Number)\n",
    "all_cal_biases1 = np.empty(Number)\n",
    "all_cal_biases2 = np.empty(Number)\n",
    "all_accuracy1 = np.empty(Number)\n",
    "all_accuracy2 = np.empty(Number)\n",
    "test_coh1 = 0.15\n",
    "test_coh2 = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f76e52b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias_pre = Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "Confusion Matrix: (target in columns)\n",
      "[[   0.    0.]\n",
      " [1000. 1000.]]\n",
      "Confusion Matrix: (target in columns)\n",
      "[[1000.  632.]\n",
      " [   0.  368.]]\n",
      "weights after preliminary training = Parameter containing:\n",
      "tensor([[0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099]])\n",
      "gain after preliminary training = Parameter containing:\n",
      "tensor([1.])\n",
      "bias after preliminary training= Parameter containing:\n",
      "tensor([-0.3660], requires_grad=True)\n",
      "weights before training = Parameter containing:\n",
      "tensor([[0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099]])\n",
      "gain before training = Parameter containing:\n",
      "tensor([1.])\n",
      "bias before training = Parameter containing:\n",
      "tensor([-0.3660], requires_grad=True)\n",
      "Confusion Matrix: (target in columns)\n",
      "[[1000.   78.]\n",
      " [   0.  922.]]\n",
      "weights after training = Parameter containing:\n",
      "tensor([[0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
      "         0.0099]])\n",
      "gain after training = Parameter containing:\n",
      "tensor([1.])\n",
      "bias after training = Parameter containing:\n",
      "tensor([-0.1444], requires_grad=True)\n",
      "-2.1089422939606988\n",
      "0.684\n",
      "Parameter containing:\n",
      "tensor([-0.3660], requires_grad=True)\n",
      "-1.1026531249418756\n",
      "0.961\n",
      "Parameter containing:\n",
      "tensor([-0.1444], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for ixx in range(Number):\n",
    "    #######################\n",
    "\n",
    "    def main(num_epochs = 1000, lr = 1e-1, batch_size = 100, learning_rule = 'backprop', model = None): # learning_rule can be 'backprop' or 'global_gain'\n",
    "\n",
    "    #     torch.manual_seed(0)\n",
    "    #     np.random.seed(0)\n",
    "\n",
    "        if model is None:\n",
    "            model = Sensorimotor(num_sensory_neurons = 100, \n",
    "                             sensory_plastic = False, \n",
    "                             readout_plastic = False,\n",
    "                             gain_plastic = False,\n",
    "                             bias_plastic = True,\n",
    "                             sensory_pop_ratio = 0.2,\n",
    "                             num_classes = 1)\n",
    "\n",
    "    #     print(model)\n",
    "    #     print(model.readout.readout_layer.weight)\n",
    "    #     print('\\n===========Check Grad============')\n",
    "    #     for name, param in model.named_parameters():\n",
    "    #         print(name, param.requires_grad)\n",
    "    #     print('=================================\\n')    \n",
    "\n",
    "        params = model.parameters()\n",
    "\n",
    "\n",
    "        optimizer = optim.SGD(params, lr=lr, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "    #     loss = nn.CrossEntropyLoss()\n",
    "    #     loss = nn.NLLLoss()\n",
    "    #     loss = nn.MSELoss()\n",
    "        loss = nn.BCELoss(reduction='mean')\n",
    "\n",
    "        dataset_train = Stimulus(min_coherence = .5, max_coherence = 1) # set the range of coherences\n",
    "        dataset_valid = Stimulus(min_coherence = test_coh1, max_coherence = test_coh2)\n",
    "    #     dataset_valid = Stimulus(min_coherence = 0.04, max_coherence = 0.06)\n",
    "\n",
    "\n",
    "        sampler_train = data.RandomSampler(dataset_train)\n",
    "        train_dl = data.DataLoader(dataset_train,\n",
    "                                 batch_size=batch_size,\n",
    "                                 sampler=sampler_train,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=0,\n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=True)\n",
    "\n",
    "        sampler_valid = data.RandomSampler(dataset_valid)\n",
    "        valid_dl = data.DataLoader(dataset_valid,\n",
    "                                 batch_size=batch_size,\n",
    "                                 sampler=sampler_valid,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=0,\n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "        all_loss = []\n",
    "        all_loss_valid = []\n",
    "        print(f'bias_pre = {model.readout.readout_bias}')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            Loss = 0\n",
    "\n",
    "            for stimulus, target in train_dl:\n",
    "\n",
    "                decision, _ = model(stimulus)\n",
    "                L = loss(decision, target)\n",
    "    #             print(f'dec={decision}, t={target.squeeze()}, loss={L}')\n",
    "\n",
    "                Loss += L/len(train_dl)\n",
    "    #             print(f'bias = {model.readout.readout_layer.bias}', f'loss = {Loss}')\n",
    "                optimizer.zero_grad()\n",
    "                L.backward()      \n",
    "\n",
    "                if learning_rule != 'backprop':\n",
    "                    model = personalized_backward(model, stimulus, target, method=learning_rule)\n",
    "\n",
    "\n",
    "                optimizer.step()\n",
    "                del L\n",
    "\n",
    "\n",
    "            Loss_valid = 0\n",
    "            conf_mat = ConfusionMeter(num_class=2)\n",
    "            i = 0\n",
    "            y1 = []\n",
    "            y0 = []\n",
    "            for stimulus, target in valid_dl:\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    decision, readout = model(stimulus)\n",
    "\n",
    "                    pred = decision.clone()\n",
    "\n",
    "                    decision_copy = decision.clone()\n",
    "                    pred = target.clone()\n",
    "    #                 y1.extend(readout[:,1].detach())\n",
    "    #                 y0.extend(readout[:,0].detach())\n",
    "    #                 idx1 = decision_copy[:,1] < decision_copy[:,0]\n",
    "    #                 idx2 = decision_copy[:,1] >= decision_copy[:,0]\n",
    "                    idx1 = decision_copy < 0.5\n",
    "                    idx2 = decision_copy >= 0.5\n",
    "                    pred[idx1] = 0\n",
    "                    pred[idx2] = 1\n",
    "\n",
    "                    target_copy = target.squeeze().int()\n",
    "                    conf_mat.update(pred.int(),target_copy)\n",
    "                    del pred\n",
    "                    L = loss(decision, target)\n",
    "                    Loss_valid += L/len(train_dl)\n",
    "\n",
    "    #                 \n",
    "\n",
    "                    del L\n",
    "            if epoch == 0:\n",
    "                conf_mat.print_mat()\n",
    "\n",
    "            all_loss.append(Loss)\n",
    "            all_loss_valid.append(Loss_valid)\n",
    "\n",
    "        conf_mat.print_mat()\n",
    "        conf1 = conf_mat.mat\n",
    "        print(f'weights after preliminary training = {model.readout.readout_weight}')\n",
    "        print(f'gain after preliminary training = {model.readout.readout_gain}')\n",
    "        print(f'bias after preliminary training= {model.readout.readout_bias}')\n",
    "        bias1 = model.readout.readout_bias\n",
    "\n",
    "\n",
    "            # print(f'epoch {epoch},   training Loss = {Loss},   validation Loss = {Loss_valid}')\n",
    "        return all_loss, all_loss_valid, model, y0, y1,conf1,bias1\n",
    "\n",
    "\n",
    "    def personalized_backward(model, stimulus, target, method = 'global_gain'):\n",
    "\n",
    "        if method == 'global_gain': \n",
    "            # only adds to the weight value:  if weight is negative (positive) adds a negative (positive) value \n",
    "            for n,p in model.named_parameters():\n",
    "\n",
    "                if p.requires_grad:\n",
    "    #                 print(f'{n}, mean = {p.mean()}, std = {p.std()}')\n",
    "                    p_sign = p.clone()\n",
    "                    p_sign[p_sign>0] = 1\n",
    "                    p_sign[p_sign<0] = -1\n",
    "                    p.grad = -1*torch.ones((p.grad.shape),requires_grad=True)*p_sign\n",
    "\n",
    "        if method == 'hebbian': \n",
    "\n",
    "            for n,p in model.named_parameters():\n",
    "\n",
    "                if ('readout' in n) and ('weight' in n):\n",
    "                    output = model(stimulus)\n",
    "                    s_out = model.sensory_pop(stimulus)\n",
    "                    hebb_factor = torch.matmul(output.transpose(1,0),s_out)/s_out.shape[0]\n",
    "                    p.grad = hebb_factor\n",
    "\n",
    "        if method == 'hebbian_wfb':\n",
    "\n",
    "            for n,p in model.named_parameters():\n",
    "\n",
    "                if ('readout' in n) and ('weight' in n):\n",
    "                    target = target.unsqueeze(0)\n",
    "\n",
    "                    # create feedback based on the target values\n",
    "                    fb = torch.cat((target,(target-1).abs()),dim=0).squeeze().transpose(1,0)\n",
    "\n",
    "                    output = model(stimulus)\n",
    "                    fb_modulated_output = output*fb\n",
    "                    s_out = model.sensory_pop(stimulus)\n",
    "                    hebb_factor = torch.matmul(fb_modulated_output.transpose(1,0),s_out)/s_out.shape[0]\n",
    "                    p.grad = hebb_factor\n",
    "\n",
    "        return model\n",
    "\n",
    "    #######################\n",
    "\n",
    "    num_epochs = 200\n",
    "    lr = .1\n",
    "    batch_size = 2000\n",
    "\n",
    "    loss, loss_valid, model, y0, y1,conf1,bias1 = main(num_epochs = num_epochs, lr = lr, batch_size = batch_size, learning_rule = 'backprop')\n",
    "\n",
    "\n",
    "    #######################\n",
    "\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    torch.save(model.state_dict(),cwd+'\\\\trained_model_new2.pt')        \n",
    "\n",
    "    \n",
    "    #######################\n",
    "\n",
    "    def main2(num_epochs = 1000, lr = 1e-1, batch_size = 100, learning_rule = 'backprop', esp_h_rate=0,esp_f_rate=0,con_h_rate=0,con_f_rate=0, ig=0,model = None): # learning_rule can be 'backprop' or 'global_gain'\n",
    "\n",
    "    #     torch.manual_seed(0)\n",
    "    #     np.random.seed(0)\n",
    "\n",
    "        if model is None:\n",
    "            model = Sensorimotor(num_sensory_neurons = 100, \n",
    "                             sensory_plastic = False, \n",
    "                             readout_plastic = False,\n",
    "                             gain_plastic = False,\n",
    "                             bias_plastic = True,\n",
    "                             sensory_pop_ratio = 0.2,\n",
    "                             num_classes = 1)\n",
    "\n",
    "\n",
    "        ########### I just add this part to the model #######\n",
    "        model.load_state_dict(torch.load(cwd+'\\\\trained_model_new2.pt'))\n",
    "        model.eval()\n",
    "        params = model.parameters()\n",
    "        ######################################################  \n",
    "\n",
    "    #     print(model)\n",
    "    #     print(model.readout.readout_layer.weight)\n",
    "    #     print('\\n===========Check Grad============')\n",
    "    #     for name, param in model.named_parameters():\n",
    "    #         print(name, param.requires_grad)\n",
    "    #     print('=================================\\n')    \n",
    "\n",
    "\n",
    "\n",
    "        optimizer = optim.SGD(params, lr=lr, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "    #     loss = nn.CrossEntropyLoss()\n",
    "    #     loss = nn.NLLLoss()\n",
    "    #     loss = nn.MSELoss()\n",
    "        loss = nn.BCELoss(reduction='mean')\n",
    "\n",
    "        dataset_train = Stimulus(min_coherence = 0.2, max_coherence = 0.3) # set the range of coherences\n",
    "        dataset_valid = Stimulus(min_coherence = test_coh1, max_coherence = test_coh2)\n",
    "    #     dataset_valid = Stimulus(min_coherence = 0.04, max_coherence = 0.06)\n",
    "\n",
    "\n",
    "        sampler_train = data.RandomSampler(dataset_train)\n",
    "        train_dl = data.DataLoader(dataset_train,\n",
    "                                 batch_size=batch_size,\n",
    "                                 sampler=sampler_train,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=0,\n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=True)\n",
    "\n",
    "        sampler_valid = data.RandomSampler(dataset_valid)\n",
    "        valid_dl = data.DataLoader(dataset_valid,\n",
    "                                 batch_size=batch_size,\n",
    "                                 sampler=sampler_valid,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=0,\n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "        all_loss = []\n",
    "        all_loss_valid = []\n",
    "        print(f'weights before training = {model.readout.readout_weight}')\n",
    "        print(f'gain before training = {model.readout.readout_gain}')\n",
    "        print(f'bias before training = {model.readout.readout_bias}')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            Loss = 0\n",
    "\n",
    "            for stimulus, target in train_dl:\n",
    "\n",
    "                decision, _ = model(stimulus)\n",
    "                L = loss(decision, target)\n",
    "    #             print(f'dec={decision}, t={target.squeeze()}, loss={L}')\n",
    "\n",
    "                Loss += L/len(train_dl)\n",
    "    #             print(f'bias = {model.readout.readout_layer.bias}', f'loss = {Loss}')\n",
    "                optimizer.zero_grad()\n",
    "                L.backward()      \n",
    "\n",
    "                if learning_rule != 'backprop':\n",
    "                    model = personalized_backward(model, stimulus, target, method=learning_rule)\n",
    "\n",
    "\n",
    "                optimizer.step()\n",
    "                del L\n",
    "\n",
    "\n",
    "            Loss_valid = 0\n",
    "            conf_mat = ConfusionMeter(num_class=2)\n",
    "            i = 0\n",
    "            y1 = []\n",
    "            y0 = []\n",
    "            for stimulus, target in valid_dl:\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    decision, readout = model(stimulus)\n",
    "\n",
    "                    pred = decision.clone()\n",
    "\n",
    "                    decision_copy = decision.clone()\n",
    "                    pred = target.clone()\n",
    "    #                 y1.extend(readout[:,1].detach())\n",
    "    #                 y0.extend(readout[:,0].detach())\n",
    "    #                 idx1 = decision_copy[:,1] < decision_copy[:,0]\n",
    "    #                 idx2 = decision_copy[:,1] >= decision_copy[:,0]\n",
    "                    idx1 = decision_copy < 0.5\n",
    "                    idx2 = decision_copy >= 0.5\n",
    "                    pred[idx1] = 0\n",
    "                    pred[idx2] = 1\n",
    "\n",
    "                    target_copy = target.squeeze().int()\n",
    "                    conf_mat.update(pred.int(),target_copy)\n",
    "                    del pred\n",
    "                    L = loss(decision, target)\n",
    "                    Loss_valid += L/len(train_dl)\n",
    "\n",
    "    #                 \n",
    "\n",
    "                    del L\n",
    "#             for ig in range(num_epochs):\n",
    "            if epoch % 10 == 0:\n",
    "#                 print(f'epoch number = {epoch}')\n",
    "#                 print(conf_mat.print_mat())\n",
    "                esp_h_rate[ig] = conf_mat.mat[1,1]\n",
    "#                 print(esp_h_rate)\n",
    "                esp_f_rate[ig] = conf_mat.mat[0,1]\n",
    "#                 print(esp_f_rate)\n",
    "                con_h_rate[ig] = conf_mat.mat[0,0]\n",
    "#                 print(con_h_rate)\n",
    "                con_f_rate[ig] = conf_mat.mat[1,0]\n",
    "#                 print(con_f_rate)\n",
    "                ig = ig +1\n",
    "\n",
    "#             if epoch == 0:\n",
    "#     #             conf1 = conf_mat.mat\n",
    "#                 conf_mat.print_mat()\n",
    "\n",
    "            all_loss.append(Loss)\n",
    "            all_loss_valid.append(Loss_valid)\n",
    "\n",
    "        conf_mat.print_mat()\n",
    "        esp_h_rate[ig] = conf_mat.mat[1,1]\n",
    "#         print(esp_h_rate)\n",
    "        esp_f_rate[ig] = conf_mat.mat[0,1]\n",
    "#         print(esp_f_rate)\n",
    "        con_h_rate[ig] = conf_mat.mat[0,0]\n",
    "#         print(con_h_rate)\n",
    "        con_f_rate[ig] = conf_mat.mat[1,0]\n",
    "#         print(con_f_rate)\n",
    "        conf2 = conf_mat.mat\n",
    "        bias2 = model.readout.readout_bias\n",
    "        print(f'weights after training = {model.readout.readout_weight}')\n",
    "        print(f'gain after training = {model.readout.readout_gain}')\n",
    "        print(f'bias after training = {model.readout.readout_bias}')\n",
    "        \n",
    "        bias_mat = np.zeros(len(esp_h_rate))\n",
    "        accur_mat = np.zeros(len(esp_h_rate))\n",
    "        for ii in range(len(esp_h_rate)):\n",
    "            con_hit_rate1 = con_h_rate[ii]/(con_h_rate[ii]+ con_f_rate[ii])\n",
    "            exp_hit_rate1 = esp_h_rate[ii]/(esp_f_rate[ii]+ esp_h_rate[ii])\n",
    "            \n",
    "            if exp_hit_rate1 >= 0.98: # to avoid infinity\n",
    "                exp_hit_rate1 = 0.98\n",
    "            if con_hit_rate1 >= 0.98:\n",
    "                con_hit_rate1 = 0.98\n",
    "            if exp_hit_rate1 <= 0.5:\n",
    "                exp_hit_rate1 = 0.5\n",
    "            if con_hit_rate1 <= 0.5:\n",
    "                con_hit_rate1 = 0.5\n",
    "            bias_test1 = ((norm.ppf(exp_hit_rate1)**2) - (norm.ppf(con_hit_rate1)**2))/2\n",
    "            Accuracy1 = (con_h_rate[ii]+esp_h_rate[ii])/(con_h_rate[ii]+ con_f_rate[ii]+esp_f_rate[ii]+ esp_h_rate[ii])\n",
    "\n",
    "            bias_mat[ii] = bias_test1\n",
    "            accur_mat[ii] = Accuracy1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            # print(f'epoch {epoch},   training Loss = {Loss},   validation Loss = {Loss_valid}')\n",
    "        return all_loss, all_loss_valid, model, y0, y1,conf2,bias2,esp_h_rate,esp_f_rate,con_h_rate,con_f_rate,bias_mat,accur_mat\n",
    "\n",
    "\n",
    "    def personalized_backward(model, stimulus, target, method = 'global_gain'):\n",
    "\n",
    "        if method == 'global_gain': \n",
    "            # only adds to the weight value:  if weight is negative (positive) adds a negative (positive) value \n",
    "            for n,p in model.named_parameters():\n",
    "\n",
    "                if p.requires_grad:\n",
    "    #                 print(f'{n}, mean = {p.mean()}, std = {p.std()}')\n",
    "                    p_sign = p.clone()\n",
    "                    p_sign[p_sign>0] = 1\n",
    "                    p_sign[p_sign<0] = -1\n",
    "                    p.grad = -1*torch.ones((p.grad.shape),requires_grad=True)*p_sign\n",
    "\n",
    "        if method == 'hebbian': \n",
    "\n",
    "            for n,p in model.named_parameters():\n",
    "\n",
    "                if ('readout' in n) and ('weight' in n):\n",
    "                    output = model(stimulus)\n",
    "                    s_out = model.sensory_pop(stimulus)\n",
    "                    hebb_factor = torch.matmul(output.transpose(1,0),s_out)/s_out.shape[0]\n",
    "                    p.grad = hebb_factor\n",
    "\n",
    "        if method == 'hebbian_wfb':\n",
    "\n",
    "            for n,p in model.named_parameters():\n",
    "\n",
    "                if ('readout' in n) and ('weight' in n):\n",
    "                    target = target.unsqueeze(0)\n",
    "\n",
    "                    # create feedback based on the target values\n",
    "                    fb = torch.cat((target,(target-1).abs()),dim=0).squeeze().transpose(1,0)\n",
    "\n",
    "                    output = model(stimulus)\n",
    "                    fb_modulated_output = output*fb\n",
    "                    s_out = model.sensory_pop(stimulus)\n",
    "                    hebb_factor = torch.matmul(fb_modulated_output.transpose(1,0),s_out)/s_out.shape[0]\n",
    "                    p.grad = hebb_factor\n",
    "\n",
    "        return model\n",
    "\n",
    "    #######################\n",
    "\n",
    "\n",
    "    num_epochs = N_epoch_t\n",
    "    lr = 0.1\n",
    "    batch_size = 2000\n",
    "\n",
    "    loss, loss_valid, model, y0, y1,conf2,bias2,esp_h_rate,esp_f_rate,con_h_rate,con_f_rate,bias_mat,accur_mat = main2(num_epochs = num_epochs, lr = lr, batch_size = batch_size, learning_rule = 'backprop',esp_h_rate = np.zeros(np.floor(num_epochs/10).astype(int)+1),esp_f_rate = np.zeros(np.floor(num_epochs/10).astype(int)+1),con_h_rate = np.zeros(np.floor(num_epochs/10).astype(int)+1),con_f_rate = np.zeros(np.floor(num_epochs/10).astype(int)+1),ig=0)\n",
    "\n",
    "    \n",
    "    bias_all_mat[ixx,] = bias_mat\n",
    "    accur_all_mat[ixx,] = accur_mat\n",
    "     #######################\n",
    "\n",
    "    # test1\n",
    "    con_hit_rate1 = conf1[0,0]/(conf1[0,0]+ conf1[1,0])\n",
    "    exp_hit_rate1 = conf1[1,1]/(conf1[0,1]+ conf1[1,1])\n",
    "    # print(con_hit_rate1)\n",
    "    # print(exp_hit_rate1)\n",
    "\n",
    "    if exp_hit_rate1 >= 0.98: # to avoid infinity\n",
    "        exp_hit_rate1 = 0.98\n",
    "    if con_hit_rate1 >= 0.98:\n",
    "        con_hit_rate1 = 0.98\n",
    "\n",
    "    if exp_hit_rate1 <= 0.5:\n",
    "        exp_hit_rate1 = 0.5\n",
    "    if con_hit_rate1 <= 0.5:\n",
    "        con_hit_rate1 = 0.5\n",
    "    bias_test1 = ((norm.ppf(exp_hit_rate1)**2) - (norm.ppf(con_hit_rate1)**2))/2\n",
    "    print(bias_test1) # bias that was calculated by signal detection theory\n",
    "    Accuracy1 = (conf1[0,0]+conf1[1,1])/(conf1[0,0]+ conf1[1,0]+conf1[0,1]+ conf1[1,1])\n",
    "    print(Accuracy1) # accuracy of the model\n",
    "    print(bias1) # bias of the model\n",
    "\n",
    "    #######################\n",
    "\n",
    "\n",
    "    # test2\n",
    "    con_hit_rate2 = conf2[0,0]/(conf2[0,0]+ conf2[1,0])\n",
    "    exp_hit_rate2 = conf2[1,1]/(conf2[0,1]+ conf2[1,1])\n",
    "    # print(con_hit_rate2)\n",
    "    # print(exp_hit_rate2)\n",
    "\n",
    "    if exp_hit_rate2 >= 0.98: # to avoid infinity\n",
    "        exp_hit_rate2 = 0.98\n",
    "    if con_hit_rate2 >= 0.98:\n",
    "        con_hit_rate2 = 0.98\n",
    "\n",
    "    if exp_hit_rate2 <= 0.5:\n",
    "        exp_hit_rate2 = 0.5\n",
    "    if con_hit_rate2 <= 0.5:\n",
    "        con_hit_rate2 = 0.5\n",
    "    bias_test2 = ((norm.ppf(exp_hit_rate2)**2) - (norm.ppf(con_hit_rate2)**2))/2\n",
    "    print(bias_test2) # bias that was calculated by signal detection theory\n",
    "    Accuracy2 = (conf2[0,0]+conf2[1,1])/(conf2[0,0]+ conf2[1,0]+conf2[0,1]+ conf2[1,1])\n",
    "    print(Accuracy2) # accuracy of the model\n",
    "    print(bias2) # bias of the model\n",
    "    \n",
    " \n",
    "    \n",
    "    all_biases1[ixx] = bias1\n",
    "    all_biases2[ixx] = bias2\n",
    "    \n",
    "    all_cal_biases1[ixx] = bias_test1\n",
    "    all_cal_biases2[ixx] = bias_test2\n",
    "    all_accuracy1[ixx] = Accuracy1\n",
    "    all_accuracy2[ixx] = Accuracy2\n",
    "     #######################\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b394093b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bb = np.transpose(all_cal_biases1)\n",
    "bb=bb[:,np.newaxis]\n",
    "final_bias_mat = np.append(bb,bias_all_mat,axis =1)\n",
    "final_bias_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e1149a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = np.transpose(all_accuracy1)\n",
    "bb=bb[:,np.newaxis]\n",
    "final_acc_mat = np.append(bb,accur_all_mat,axis =1)\n",
    "final_acc_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3fde1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.684  0.699  0.7515 0.7985 0.834  0.8645 0.891  0.9085 0.929  0.938\n",
      " 0.9495 0.961 ]\n",
      "[-2.10894229 -2.10894229 -2.10891402 -2.07878519 -2.01459181 -1.92301952\n",
      " -1.80554862 -1.70034213 -1.53501807 -1.44167469 -1.29501483 -1.10265312]\n"
     ]
    }
   ],
   "source": [
    "acc_mean = np.mean(final_acc_mat,axis=0)\n",
    "bias_mean = np.mean(final_bias_mat,axis=0)\n",
    "acc_err = np.std(final_acc_mat,axis=0)/np.sqrt(Number)\n",
    "bias_err = np.std(final_bias_mat,axis=0)/np.sqrt(Number)\n",
    "acc_std = np.std(final_acc_mat,axis=0)\n",
    "bias_std = np.std(final_bias_mat,axis=0)\n",
    "print(acc_mean)\n",
    "print(bias_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156295a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('acc_bmodel_0.15_0.65',acc_mean)\n",
    "# np.save('bias_bmodel_0.15_0.65',bias_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53e938cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(np.arange(0,int(N_epoch_t/10 +2))*10,acc_mean)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.title('Bias modulation model (0.15-0.65)')\n",
    "# plt.savefig(fname = 'Accuracy of Bias model (0.15-0.65).jpg', transparent = True, bbox_inches = 'tight', dpi = 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8e20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_mean[0:3] = bias_mean[4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b19e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(np.arange(0,int(N_epoch_t/10 +2))*10,bias_mean)\n",
    "plt.ylabel('Bias')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.title('Bias modulation model (0.15-0.65)')\n",
    "# plt.savefig(fname = 'Bias of Bias model (0.15-0.65).jpg', transparent = True, bbox_inches = 'tight', dpi = 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4d75e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684\n",
      "0.961\n",
      "-2.1089422939606988\n",
      "-1.1026531249418756\n",
      "tensor(-0.3660, grad_fn=<MeanBackward0>)\n",
      "tensor(-0.1444, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a1 = np.mean(all_accuracy1)\n",
    "a2 = np.mean(all_accuracy2)\n",
    "cal_b1 = np.mean(all_cal_biases1)\n",
    "cal_b2 = np.mean(all_cal_biases2)\n",
    "b1 = torch.mean(all_biases1)\n",
    "b2 = torch.mean(all_biases2)\n",
    "print(a1)\n",
    "print(a2)\n",
    "print(cal_b1)\n",
    "print(cal_b2)\n",
    "print(b1)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d73bc1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf1[0,1]+ conf1[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90229657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871ab08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac75b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
